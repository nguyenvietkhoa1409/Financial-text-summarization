{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "L-3pmwFaem0Z"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is the full flow of Data pipeline:\n",
        "1. Download stock data, news data from Alpaca. Datatime are rounded to next day if the news is published late.\n",
        "3. Aggregate crawled Reuters' news data.\n",
        "4. Process Reuters news data datetime value to match trading date."
      ],
      "metadata": {
        "id": "WvJkYO0EsTQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Fetch price data from Yfinance api"
      ],
      "metadata": {
        "id": "L-3pmwFaem0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3UntJ3ZlbGmV",
        "outputId": "a11f243b-9f6c-4682-bcc2-7ded1623a718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.63)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.18.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.11.3)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.0)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 222, in iter_dependencies\n",
            "    req = Requirement(req_string.strip())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/requirements.py\", line 36, in __init__\n",
            "    parsed = _parse_requirement(requirement_string)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 62, in parse_requirement\n",
            "    return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 80, in _parse_requirement\n",
            "    url, specifier, marker = _parse_requirement_details(tokenizer)\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 124, in _parse_requirement_details\n",
            "    marker = _parse_requirement_marker(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 151, in _parse_requirement_marker\n",
            "    marker = _parse_marker(tokenizer)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 266, in _parse_marker\n",
            "    expression = [_parse_marker_atom(tokenizer)]\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 291, in _parse_marker_atom\n",
            "    marker = _parse_marker_item(tokenizer)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 305, in _parse_marker_item\n",
            "    marker_var_right = _parse_marker_var(tokenizer)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 317, in _parse_marker_var\n",
            "    return process_python_str(tokenizer.read().text)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 332, in process_python_str\n",
            "    value = ast.literal_eval(python_str)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ast.py\", line 64, in literal_eval\n",
            "    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ast.py\", line 50, in parse\n",
            "    return compile(source, filename, mode, flags,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 216, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1477, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 978, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.11/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1230, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1110, in emit\n",
            "    msg = self.format(record)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 953, in format\n",
            "    return fmt.format(record)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 695, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 645, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 124, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 728, in __init__\n",
            "    self.stack = StackSummary._extract_from_extended_frame_gen(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 433, in _extract_from_extended_frame_gen\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 318, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/linecache.py\", line 30, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/tokenize.py\", line 398, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/tokenize.py\", line 367, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "            ^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/tokenize.py\", line 325, in read_or_stop\n",
            "    return readline()\n",
            "           ^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "def download_data(start_day: str, end_day: str, tickers: List[str]) -> List[pd.DataFrame]:\n",
        "    \"\"\"Downloads adjusted close price data for given tickers within a date range.\"\"\"\n",
        "    df_list = []\n",
        "    for ticker in tickers:\n",
        "        print(f'Downloading data for {ticker}')\n",
        "        # Set auto_adjust to False to include the 'Adj Close' column\n",
        "        data = yf.download(ticker, start=start_day, end=end_day)\n",
        "        data = data.reset_index()\n",
        "        data['Date'] = data['Date'].dt.date\n",
        "        data = data[['Date', 'Close']]\n",
        "        data = data.rename(columns={'Date': 'date', 'Close': ticker})\n",
        "        df_list.append(data)\n",
        "    return df_list"
      ],
      "metadata": {
        "id": "UvJPSL_ubL7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Mount gg drive and create  /content/drive/My Drive/price_data path\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create the path if it doesn't exist\n",
        "price_data_path = '/content/drive/My Drive/NCKH/price_data'\n",
        "if not os.path.exists(price_data_path):\n",
        "  os.makedirs(price_data_path)\n",
        "  print(f\"Created directory: {price_data_path}\")\n",
        "else:\n",
        "  print(f\"Directory already exists: {price_data_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq2tpWZ6b8Fi",
        "outputId": "360649dd-b3ba-4ab6-c45c-dd954c49d3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Directory already exists: /content/drive/My Drive/NCKH/price_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_day = '2023-08-17'\n",
        "end_day = '2025-04-10'\n",
        "tickers = [\"TSLA\", \"AMZN\", \"MSFT\", \"NFLX\"]\n",
        "\n",
        "df_list = download_data(start_day, end_day, tickers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vUW65Lsbm0L",
        "outputId": "3cdf5c99-6259-4a0d-e287-7fb6cafb547e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-18-1687276188.py:11: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_day, end=end_day)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-18-1687276188.py:11: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_day, end=end_day)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-18-1687276188.py:11: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_day, end=end_day)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-18-1687276188.py:11: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_day, end=end_day)\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data for TSLA\n",
            "Downloading data for AMZN\n",
            "Downloading data for MSFT\n",
            "Downloading data for NFLX\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for df in df_list:\n",
        "  print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu-MPsy09kWN",
        "outputId": "fa465b05-9b13-4451-a1bc-ae8634e57ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiIndex([('date',     ''),\n",
            "            ('TSLA', 'TSLA')],\n",
            "           names=['Price', 'Ticker'])\n",
            "MultiIndex([('date',     ''),\n",
            "            ('AMZN', 'AMZN')],\n",
            "           names=['Price', 'Ticker'])\n",
            "MultiIndex([('date',     ''),\n",
            "            ('MSFT', 'MSFT')],\n",
            "           names=['Price', 'Ticker'])\n",
            "MultiIndex([('date',     ''),\n",
            "            ('NFLX', 'NFLX')],\n",
            "           names=['Price', 'Ticker'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def combine_dataframes(df_list: List[pd.DataFrame], path: str, tickers: List[str]) -> dict:\n",
        "    \"\"\"Combines dataframes of different tickers into a single dictionary and saves it as a pickle file.\"\"\"\n",
        "    df_dicts = [dict(zip(df[('date', '')], df[(ticker, ticker)])) for df, ticker in zip(df_list, tickers)]\n",
        "    combined_dict = {date: {'price': {}} for df_dict in df_dicts for date in df_dict}\n",
        "    for i, df_dict in enumerate(df_dicts):\n",
        "        for date, price in df_dict.items():\n",
        "            combined_dict[date]['price'][tickers[i]] = price\n",
        "    pkl_filename = path + 'price.pkl'\n",
        "    with open(pkl_filename, 'wb') as file:\n",
        "        pickle.dump(combined_dict, file)\n",
        "    print(f'Price data saved to: {pkl_filename}')\n",
        "    return combined_dict"
      ],
      "metadata": {
        "id": "98Uhkfp9iv2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os # Import the os module\n",
        "\n",
        "price_path = '/content/drive/My Drive/NCKH/price_data/' # Corrected path\n",
        "data = pd.read_pickle(os.path.join(price_path, \"price_data.pkl\")) # Use os.path.join\n",
        "\n",
        "# Print the first 5 items of the dictionary\n",
        "for item in list(data.items())[:5]:\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "id": "dor-UuL0GVf6",
        "outputId": "6389bdf0-e707-42dc-abe7-a1023f20bddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m(\u001b[0m\n",
              "    \u001b[1;35mdatetime.date\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2023\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m17\u001b[0m\u001b[1m)\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'price'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'TSLA'\u001b[0m: \u001b[1;36m219.22000122070312\u001b[0m, \u001b[32m'AMZN'\u001b[0m: \u001b[1;36m133.97999572753906\u001b[0m, \u001b[32m'MSFT'\u001b[0m: \u001b[1;36m312.6887512207031\u001b[0m, \u001b[32m'NFLX'\u001b[0m: \u001b[1;36m403.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.date</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span><span style=\"font-weight: bold\">)</span>,\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'price'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'TSLA'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">219.22000122070312</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'AMZN'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">133.97999572753906</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'MSFT'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">312.6887512207031</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'NFLX'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">403.0</span><span style=\"font-weight: bold\">}}</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m(\u001b[0m\n",
              "    \u001b[1;35mdatetime.date\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2023\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m18\u001b[0m\u001b[1m)\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'price'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'TSLA'\u001b[0m: \u001b[1;36m215.49000549316406\u001b[0m,\n",
              "            \u001b[32m'AMZN'\u001b[0m: \u001b[1;36m133.22000122070312\u001b[0m,\n",
              "            \u001b[32m'MSFT'\u001b[0m: \u001b[1;36m312.2939758300781\u001b[0m,\n",
              "            \u001b[32m'NFLX'\u001b[0m: \u001b[1;36m404.5299987792969\u001b[0m\n",
              "        \u001b[1m}\u001b[0m\n",
              "    \u001b[1m}\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.date</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span><span style=\"font-weight: bold\">)</span>,\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'price'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'TSLA'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">215.49000549316406</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'AMZN'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">133.22000122070312</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'MSFT'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">312.2939758300781</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'NFLX'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">404.5299987792969</span>\n",
              "        <span style=\"font-weight: bold\">}</span>\n",
              "    <span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m(\u001b[0m\n",
              "    \u001b[1;35mdatetime.date\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2023\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m21\u001b[0m\u001b[1m)\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'price'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'TSLA'\u001b[0m: \u001b[1;36m231.27999877929688\u001b[0m,\n",
              "            \u001b[32m'AMZN'\u001b[0m: \u001b[1;36m134.67999267578125\u001b[0m,\n",
              "            \u001b[32m'MSFT'\u001b[0m: \u001b[1;36m317.62261962890625\u001b[0m,\n",
              "            \u001b[32m'NFLX'\u001b[0m: \u001b[1;36m408.2900085449219\u001b[0m\n",
              "        \u001b[1m}\u001b[0m\n",
              "    \u001b[1m}\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.date</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span><span style=\"font-weight: bold\">)</span>,\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'price'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'TSLA'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">231.27999877929688</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'AMZN'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">134.67999267578125</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'MSFT'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">317.62261962890625</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'NFLX'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">408.2900085449219</span>\n",
              "        <span style=\"font-weight: bold\">}</span>\n",
              "    <span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m(\u001b[0m\n",
              "    \u001b[1;35mdatetime.date\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2023\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m22\u001b[0m\u001b[1m)\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'price'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'TSLA'\u001b[0m: \u001b[1;36m233.19000244140625\u001b[0m,\n",
              "            \u001b[32m'AMZN'\u001b[0m: \u001b[1;36m134.25\u001b[0m,\n",
              "            \u001b[32m'MSFT'\u001b[0m: \u001b[1;36m318.19488525390625\u001b[0m,\n",
              "            \u001b[32m'NFLX'\u001b[0m: \u001b[1;36m413.1700134277344\u001b[0m\n",
              "        \u001b[1m}\u001b[0m\n",
              "    \u001b[1m}\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.date</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span><span style=\"font-weight: bold\">)</span>,\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'price'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'TSLA'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">233.19000244140625</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'AMZN'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">134.25</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'MSFT'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">318.19488525390625</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'NFLX'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">413.1700134277344</span>\n",
              "        <span style=\"font-weight: bold\">}</span>\n",
              "    <span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m(\u001b[0m\n",
              "    \u001b[1;35mdatetime.date\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2023\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m23\u001b[0m\u001b[1m)\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'price'\u001b[0m: \u001b[1m{\u001b[0m\n",
              "            \u001b[32m'TSLA'\u001b[0m: \u001b[1;36m236.86000061035156\u001b[0m,\n",
              "            \u001b[32m'AMZN'\u001b[0m: \u001b[1;36m135.52000427246094\u001b[0m,\n",
              "            \u001b[32m'MSFT'\u001b[0m: \u001b[1;36m322.67486572265625\u001b[0m,\n",
              "            \u001b[32m'NFLX'\u001b[0m: \u001b[1;36m427.54998779296875\u001b[0m\n",
              "        \u001b[1m}\u001b[0m\n",
              "    \u001b[1m}\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.date</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"font-weight: bold\">)</span>,\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'price'</span>: <span style=\"font-weight: bold\">{</span>\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'TSLA'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">236.86000061035156</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'AMZN'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">135.52000427246094</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'MSFT'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">322.67486572265625</span>,\n",
              "            <span style=\"color: #008000; text-decoration-color: #008000\">'NFLX'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">427.54998779296875</span>\n",
              "        <span style=\"font-weight: bold\">}</span>\n",
              "    <span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.exists(\"/content/drive/My Drive/NCKH/price_data/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHE_XGOns6qR",
        "outputId": "7b542a03-5245-47c1-db6b-35c457900f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Fetch data from Alpaca Api.\n"
      ],
      "metadata": {
        "id": "UJdUBmS5Cej3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##a. Alpaca document instruction\n"
      ],
      "metadata": {
        "id": "ktJIvWD8E8ov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is data fetching instruction provided by Alpaca documentation. I do this as an example to understand the retrieved data structure."
      ],
      "metadata": {
        "id": "Yh5EPWO8NqZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://data.alpaca.markets/v1beta1/news\"\n",
        "\n",
        "headers = {\n",
        "    \"accept\": \"application/json\",\n",
        "    \"APCA-API-KEY-ID\": \"PK900CRTGLIE97VJER4F\",\n",
        "    \"APCA-API-SECRET-KEY\": \"PWkMvZCTT0ajJcX3O7xSCxDOyCnxaXUaCPQKuHTS\"\n",
        "}\n",
        "\n",
        "params = {\n",
        "    'start': '2024-08-17',\n",
        "    'end': '2024-08-20',\n",
        "    'sort': 'asc',\n",
        "    'symbols': 'TSLA,NFLX,MSFT,AMZN,COIN',\n",
        "    'limit': 50,\n",
        "    'include_content': True,\n",
        "    'exclude_contentless': True\n",
        "}\n",
        "\n",
        "response = requests.get(url, params = params, headers=headers)"
      ],
      "metadata": {
        "id": "oCv8IXGoMRVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import json\n",
        "\n",
        "# Parse the JSON string in response.text\n",
        "data = json.loads(response.text)\n",
        "\n",
        "# Print the keys of the main dictionary\n",
        "print(\"Keys in the response:\")\n",
        "print(data.keys())\n",
        "\n",
        "print(\"Total retrieved news:\")\n",
        "print(len(data['news']))\n",
        "\n",
        "# If the main structure is a dictionary and contains a list (like 'news'),\n",
        "# you can inspect the structure of an item in the list.\n",
        "if 'news' in data and isinstance(data['news'], list) and len(data['news']) > 0:\n",
        "    print(\"\\nKeys in the first news item:\")\n",
        "    print(data['news'][0].keys())\n",
        "\n",
        "    print(\"\\nSample of the first news item:\")\n",
        "    display(data['news'][0])\n",
        "elif isinstance(data, list) and len(data) > 0:\n",
        "    print(\"\\nKeys in the first item of the list response:\")\n",
        "    print(data[0].keys())\n",
        "\n",
        "    print(\"\\nSample of the first item:\")\n",
        "    display(data[0])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fG2PRTQONaqD",
        "outputId": "08ee787b-2bdb-40db-cd52-b0a6a223e573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in the response:\n",
            "dict_keys(['news', 'next_page_token'])\n",
            "Total retrieved news:\n",
            "27\n",
            "\n",
            "Keys in the first news item:\n",
            "dict_keys(['author', 'content', 'created_at', 'headline', 'id', 'images', 'source', 'summary', 'symbols', 'updated_at', 'url'])\n",
            "\n",
            "Sample of the first news item:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'author': 'Anan Ashraf',\n",
              " 'content': '<p>EV giant <strong>Tesla Inc.</strong> (NASDAQ:<a class=\"ticker\" href=\"https://www.benzinga.com/stock/TSLA#NASDAQ\">TSLA</a>) has a massive edge on the bridge between <a href=\"https://www.benzinga.com/news/24/02/36946524/investor-presentation-on-elon-musks-xai-reportedly-flexes-muskonomy-draws-parallels-with-openais-tra\">AI and the physical world</a>, thanks to its factories, <strong>Elon Musk</strong>&#8216;s biographer <strong>Ashlee Vance </strong>said on Friday, citing an unnamed AI expert.</p>\\n\\n\\n\\n<p><strong>What Happened:</strong> Vance took to X to detail the several ways in which Tesla has an edge over rivals owing to Musk&#8217;s portfolio of companies and several factories. Vance said that the opinion belonged to an individual with &#8220;very deep knowledge of AI and modern factories.&#8221; The biographer, however, did not name the person, saying that he is &#8220;not allowed&#8221; to do so.</p>\\n\\n\\n\\n<p>&#8220;I think none of the other companies will be as able to follow,&#8221; Vance quoted the expert as saying. Though people don&#8217;t count Musk&#8217;s companies individually as among the Big Tech empire, they collectively have something the other Big Tech players can&#8217;t match, they added. </p>\\n\\n\\n\\n<p>&#8220;I am still fairly long Elon Empire companies.&#8221; the expert added, according to Vance.</p>\\n\\n\\n\\n<figure class=\"wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter\"><div class=\"wp-block-embed__wrapper\">\\n<blockquote class=\"twitter-tweet\" data-width=\"500\" data-dnt=\"true\"><p lang=\"en\" dir=\"ltr\">&quot;I am still fairly long Elon Empire companies.&quot;</p>&mdash; Ashlee Vance (@ashleevance) <a href=\"https://twitter.com/ashleevance/status/1824578357062930590?ref_src=twsrc%5Etfw\">August 16, 2024</a></blockquote><script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\\n</div></figure>\\n\\n\\n\\n<p>Unlike robotics companies which do not have a great first customer, Tesla can test its humanoid robots in its own factories, the individual said, while noting that most others don&#8217;t have factories.</p>\\n\\n\\n\\n<p>&#8220;I think that will be extremely important when the physical part of AI starts to kick in. Being able to bridge the AI into the physical world will be extremely massive,&#8221; the expert reportedly added. </p>\\n\\n\\n\\n<figure class=\"wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter\"><div class=\"wp-block-embed__wrapper\">\\n<blockquote class=\"twitter-tweet\" data-width=\"500\" data-dnt=\"true\"><p lang=\"en\" dir=\"ltr\">&quot;I think that will be extrmely important when the physical part of AI starts to kick in. Being able to bridge the AI into the physical world will be extremely massive.<br><br>&quot;I think none of the other companies will be as able to follow.&quot;</p>&mdash; Ashlee Vance (@ashleevance) <a href=\"https://twitter.com/ashleevance/status/1824578354919641457?ref_src=twsrc%5Etfw\">August 16, 2024</a></blockquote><script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\\n</div></figure>\\n\\n\\n\\n<p><strong>Vance&#8217;s Take:</strong> Vance noted that he might have underestimated the advantage of having actual factories. &#8220;It is super unique that Musk Co can drag people from Tesla, for example, to stand up GPU datacenter for Grok in record time too,&#8221; the biographer said. </p>\\n\\n\\n\\n<p>The biographer also drew a parallel between Musk&#8217;s network of companies and <strong>General Electric</strong>. GE is another conglomerate that has stretched across major industries, he noted.</p>\\n\\n\\n\\n<p>&#8220;Musk Co seems to benefit from keeping the companies separate and more nimble but having a common CEO who can put people wherever he wants, whenever,&#8221; Vance added.</p>\\n\\n\\n\\n<figure class=\"wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter\"><div class=\"wp-block-embed__wrapper\">\\n<blockquote class=\"twitter-tweet\" data-width=\"500\" data-dnt=\"true\"><p lang=\"en\" dir=\"ltr\">I guess a GE is a historical comparion as a conglomerate that stretched across major industries. Musk Co seems to benefit from keeping the companies separate and more nimble but having a common CEO who can put people wherever he wants, whenever</p>&mdash; Ashlee Vance (@ashleevance) <a href=\"https://twitter.com/ashleevance/status/1824578361416618252?ref_src=twsrc%5Etfw\">August 16, 2024</a></blockquote><script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\\n</div></figure>\\n\\n\\n\\n<p>Vance&#8217;s biography of Musk, titled &#8220;Elon Musk: Tesla, SpaceX, and the Quest for a Fantastic Future,&#8221; was released in May 2015. </p>\\n\\n\\n\\n<p><strong>Why It Matters:</strong> Vance, or the unnamed AI expert, is not the sole player to appreciate the collaboration between different Musk-led companies. The term &#8220;<a href=\"https://www.benzinga.com/analyst-ratings/analyst-color/24/05/38939175/elon-musks-ai-ambitions-tied-to-teslas-success-says-morgan-stanley-analyst-more-con\">Muskonomy</a>&#8221; is often used to refer to Musk&#8217;s business ecosystem. </p>\\n\\n\\n\\n<p>The billionaire entrepreneur\\'s different companies are not new to collaboration either. Earlier this year, Musk said that Tesla&#8217;s upcoming Roadster vehicle was enabled by a&nbsp;<a href=\"https://www.benzinga.com/news/24/03/37814461/tesla-ceo-elon-musk-says-upcoming-roadster-not-even-really-a-car-and-would-be-cooler-than-the-cybert\" target=\"_blank\" rel=\"noreferrer noopener\">collaboration between&nbsp;</a>Tesla and his rocket manufacturing company&nbsp;<strong>SpaceX</strong>.&nbsp;</p>\\n\\n\\n\\n<p>In addition to his more popular Tesla and SpaceX, Musk is also the founder of The Boring Company and Chairman of <strong>X Corp.</strong>, the company that owns social media platform <strong>X</strong>, formerly called <strong>Twitter</strong>.</p>\\n\\n\\n\\n<p><em>Check out more of Benzinga&#8217;s Future Of Mobility coverage by&nbsp;</em><a href=\"https://www.benzinga.com/topic/mobility\" target=\"_blank\" rel=\"noreferrer noopener\"><em>following this link</em></a>.</p>\\n\\n\\n\\n<p><strong>Read More:</strong></p>\\n\\n\\n\\n<ul>\\n<li><strong><a href=\"https://www.benzinga.com/news/24/08/40427830/ula-owners-in-talks-to-sell-spacex-rival-to-sierra-space-report\">ULA Owners In Talks To Sell SpaceX Rival To Sierra Space: Report</a></strong></li>\\n</ul>\\n\\n\\n\\n<p><em>Image made via photos on Shutterstock</em></p>',\n",
              " 'created_at': '2024-08-17T03:14:27Z',\n",
              " 'headline': \"Elon Musk's Biographer Cites Unnamed AI Expert To Note That Tesla Has 'Massive Edge On Bridge Between AI And Physical World' With Its Factories\",\n",
              " 'id': 40427999,\n",
              " 'images': [{'size': 'large',\n",
              "   'url': 'https://cdn.benzinga.com/files/imagecache/2048x1536xUP/images/story/2024/08/16/Tesla-CEO-Elon-Musk-pay.jpeg'},\n",
              "  {'size': 'small',\n",
              "   'url': 'https://cdn.benzinga.com/files/imagecache/1024x768xUP/images/story/2024/08/16/Tesla-CEO-Elon-Musk-pay.jpeg'},\n",
              "  {'size': 'thumb',\n",
              "   'url': 'https://cdn.benzinga.com/files/imagecache/250x187xUP/images/story/2024/08/16/Tesla-CEO-Elon-Musk-pay.jpeg'}],\n",
              " 'source': 'benzinga',\n",
              " 'summary': 'EV giant Tesla Inc has a massive edge on the bridge between AI and the physical world, thanks to its factories, Elon Musk&#39;s biographer Ashlee Vance said on Friday, citing an unnamed AI expert.',\n",
              " 'symbols': ['TSLA'],\n",
              " 'updated_at': '2024-08-17T03:14:28Z',\n",
              " 'url': 'https://www.benzinga.com/news/24/08/40427999/elon-musks-biographer-cites-unnamed-ai-expert-to-note-that-tesla-has-massive-edge-on-bridge-between'}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Next_page_token\" is none means that we reach the end of the page."
      ],
      "metadata": {
        "id": "1IGfnYXKUT4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_page_token = data['next_page_token']\n",
        "print(next_page_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxbtbRvST5aS",
        "outputId": "3ac09ca4-3b9e-497b-eb77-73b804fe2ad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##b. Fetching Alpaca news for project\n"
      ],
      "metadata": {
        "id": "ARa20splC5S2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dependencies\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import httpx\n",
        "import tenacity\n",
        "import polars as pl\n",
        "from rich import print\n",
        "from tqdm import tqdm\n",
        "from uuid import uuid4\n",
        "from datetime import date, timedelta, datetime\n",
        "from typing import List, Dict, Tuple, Union\n",
        "from tenacity import retry, stop_after_attempt, wait_fixed"
      ],
      "metadata": {
        "id": "3qpAkRl9CxBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "END_POINT_TEMPLATE = \"https://data.alpaca.markets/v1beta1/news?start={start_date}&end={end_date}&limit=50&symbols={symbol}\"\n",
        "END_POINT_TEMPLATE_LINK_PAGE = \"https://data.alpaca.markets/v1beta1/news?limit=50&symbol={symbol}&page_token={page_token}\"\n",
        "NUM_NEWS_PER_RECORD = 200\n",
        "MAX_ATTEMPTS = 5\n",
        "WAIT_TIME = 60\n",
        "MAX_WORKERS = 30"
      ],
      "metadata": {
        "id": "cb-2ki2jDTEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def round_to_next_day(date: pl.Expr) -> pl.Expr:\n",
        "    # Check the condition for rolling over to the next day\n",
        "    condition = (date.dt.hour() >= 16) & ((date.dt.minute() > 0) | (date.dt.second() > 0))\n",
        "\n",
        "    # Use when().then().otherwise() with offset_by to correctly handle date rollovers\n",
        "    return pl.when(condition).then(date.dt.offset_by(\"1d\")).otherwise(date)"
      ],
      "metadata": {
        "id": "W60ycZQ0DixO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScraperError(Exception):\n",
        "    pass"
      ],
      "metadata": {
        "id": "0LimLEqTDl19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RecordContainerFull(Exception):\n",
        "    pass"
      ],
      "metadata": {
        "id": "5frsSPz1Do4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ParseRecordContainer:\n",
        "    def __init__(self, symbol: str) -> None:\n",
        "        self.symbol = symbol\n",
        "        self.record_counter = 0\n",
        "        self.author_list = []\n",
        "        self.content_list = []\n",
        "        self.date_list = []\n",
        "        self.source_list = []\n",
        "        self.summary_list = []\n",
        "        self.title_list = []\n",
        "        self.url_list = []\n",
        "\n",
        "    def add_records(self, records: List[Dict[str, str]]) -> None:\n",
        "        for cur_record in records:\n",
        "            self.author_list.append(cur_record[\"author\"])\n",
        "            self.content_list.append(cur_record[\"content\"])\n",
        "            date = cur_record[\"created_at\"].rstrip(\"Z\")\n",
        "            self.date_list.append(datetime.fromisoformat(date))\n",
        "            self.source_list.append(cur_record[\"source\"])\n",
        "            self.summary_list.append(cur_record[\"summary\"])\n",
        "            self.title_list.append(cur_record[\"headline\"])\n",
        "            self.url_list.append(cur_record[\"url\"])\n",
        "            self.record_counter += 1\n",
        "            if self.record_counter == NUM_NEWS_PER_RECORD:\n",
        "                raise RecordContainerFull\n",
        "\n",
        "    def pop(self, align_next_date: bool = True) -> Union[pl.DataFrame, None]:\n",
        "        if self.record_counter == 0:\n",
        "            return None\n",
        "        return_df = pl.DataFrame(\n",
        "            {\n",
        "                \"author\": self.author_list,\n",
        "                \"content\": self.content_list,\n",
        "                \"datetime\": self.date_list,\n",
        "                \"source\": self.source_list,\n",
        "                \"summary\": self.summary_list,\n",
        "                \"title\": self.title_list,\n",
        "                \"url\": self.url_list,\n",
        "            }\n",
        "        )\n",
        "        if align_next_date:\n",
        "            return_df = return_df.with_columns(\n",
        "                round_to_next_day(return_df[\"datetime\"]).alias(\"date\"),\n",
        "            )\n",
        "        else:\n",
        "            return_df = return_df.with_columns(\n",
        "                pl.col(\"datetime\").date().alias(\"date\"),\n",
        "            )\n",
        "        return return_df.with_columns(pl.lit(self.symbol).alias(\"equity\"))"
      ],
      "metadata": {
        "id": "yUV8yEqWDpcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@retry(stop=stop_after_attempt(MAX_ATTEMPTS), wait=wait_fixed(WAIT_TIME))\n",
        "def query_one_record(args: Tuple[date, str], temp_dir: str, include_content: bool = False, exclude_contentless = False) -> None:\n",
        "    date, symbol = args\n",
        "    next_date = date + timedelta(days=1)\n",
        "    request_header = {\n",
        "    \"APCA-API-KEY-ID\": \"PK900CRTGLIE97VJER4F\",\n",
        "    \"APCA-API-SECRET-KEY\": \"PWkMvZCTT0ajJcX3O7xSCxDOyCnxaXUaCPQKuHTS\",\n",
        "    }\n",
        "    container = ParseRecordContainer(symbol)\n",
        "    with httpx.Client() as client:\n",
        "        # first request\n",
        "        url = END_POINT_TEMPLATE.format(\n",
        "            start_date=date.strftime(\"%Y-%m-%d\"),\n",
        "            end_date=next_date.strftime(\"%Y-%m-%d\"),\n",
        "            symbol=symbol,\n",
        "        )\n",
        "        if include_content:\n",
        "             url += \"&include_content=True\"\n",
        "        if exclude_contentless:\n",
        "             url += \"&exclude_contentless=True\"\n",
        "\n",
        "        response = client.get(\n",
        "            url,\n",
        "            headers=request_header,\n",
        "        )\n",
        "        if response.status_code != 200:\n",
        "            print(\"[red]Hit limit[/red]\")\n",
        "            raise ScraperError(response.text)\n",
        "        result = response.json()\n",
        "        next_page_token = result[\"next_page_token\"]\n",
        "        container.add_records(result[\"news\"])\n",
        "\n",
        "        while next_page_token:\n",
        "            try:\n",
        "                url = END_POINT_TEMPLATE_LINK_PAGE.format(\n",
        "                    symbol=symbol, page_token=next_page_token\n",
        "                )\n",
        "                if include_content:\n",
        "                     url += \"&include_content=True\"\n",
        "                if exclude_contentless:\n",
        "                     url += \"&exclude_contentless=True\"\n",
        "\n",
        "                response = client.get(\n",
        "                    url,\n",
        "                    headers=request_header,\n",
        "                )\n",
        "                if response.status_code != 200:\n",
        "                    raise ScraperError(response.text)\n",
        "                result = response.json()\n",
        "                next_page_token = result[\"next_page_token\"]\n",
        "                container.add_records(result[\"news\"])\n",
        "            except RecordContainerFull:\n",
        "                break\n",
        "\n",
        "    result = container.pop(align_next_date=True)\n",
        "    if result is not None:\n",
        "        result.write_parquet(os.path.join(temp_dir, f\"{uuid4()}.parquet\"))"
      ],
      "metadata": {
        "id": "Bz6GDNvRDwsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_sync() -> None:\n",
        "    # load data\n",
        "    import pandas as pd\n",
        "    # Assuming the price data is already in the correct path as previously defined\n",
        "    price_data_path = r'/content/drive/My Drive/NCKH/price_data/price_data.pkl' # Using the previously defined price_path structure\n",
        "    with open(price_data_path, 'rb') as f:\n",
        "        combined_price_data = pickle.load(f)\n",
        "\n",
        "    # Convert the dictionary data to a list of dictionaries suitable for Polars\n",
        "    price_records = []\n",
        "    for date, data in combined_price_data.items():\n",
        "        if 'price' in data:\n",
        "            for ticker, price in data['price'].items():\n",
        "                price_records.append({\"date\": date, \"equity\": ticker, \"price\": price})\n",
        "\n",
        "    # Convert the list of dictionaries to a Polars DataFrame\n",
        "    data = pl.DataFrame(price_records)\n",
        "\n",
        "    # Define the base directory for news data\n",
        "    news_data_base_path = '/content/drive/My Drive/NCKH/news_data'\n",
        "    temp_dir = os.path.join(news_data_base_path, \"temp\")\n",
        "    primary_dir = os.path.join(news_data_base_path, \"03_primary\")\n",
        "\n",
        "    # Prepare directories\n",
        "    if os.path.exists(temp_dir):\n",
        "        shutil.rmtree(temp_dir)\n",
        "    os.makedirs(temp_dir, exist_ok=True) # Use exist_ok=True to avoid error if parent dirs don't exist\n",
        "\n",
        "    if not os.path.exists(primary_dir):\n",
        "        os.makedirs(primary_dir, exist_ok=True) # Ensure primary directory exists\n",
        "\n",
        "\n",
        "    # Extract unique (date, equity) pairs\n",
        "    query_data = (\n",
        "        data.select([\"date\", \"equity\"])\n",
        "        .unique()\n",
        "        .to_dict()\n",
        "    )\n",
        "\n",
        "\n",
        "    args_list = list(zip(query_data[\"date\"], query_data[\"equity\"]))\n",
        "    with tqdm(total=len(args_list)) as pbar:\n",
        "        for i, arg in enumerate(args_list):\n",
        "            try:\n",
        "                # Pass the temp directory and include_content=True to query_one_record\n",
        "                query_one_record(arg, temp_dir, include_content=True, exclude_contentless= True)\n",
        "            except tenacity.RetryError as e:\n",
        "                print(f\"We caught the error: {e}\")\n",
        "            pbar.update(1)\n",
        "            if (i + 1) % 3000 == 0:\n",
        "                time.sleep(90)\n",
        "\n",
        "    # Combine temporary files\n",
        "    record_dfs = [\n",
        "        pl.read_parquet(os.path.join(temp_dir, f))\n",
        "        for f in os.listdir(temp_dir) if f.endswith(\".parquet\") # Only read parquet files\n",
        "    ]\n",
        "\n",
        "    if record_dfs: # Check if there are any dataframes to concatenate\n",
        "        df = pl.concat(record_dfs)\n",
        "        df.write_parquet(os.path.join(primary_dir, \"news.parquet\"))\n",
        "        print(f\"Combined news data saved to: {os.path.join(primary_dir, 'news.parquet')}\")\n",
        "        print(df.shape)\n",
        "    else:\n",
        "        print(\"No news data was successfully downloaded and processed.\")"
      ],
      "metadata": {
        "id": "lBjxJxD3D_ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main_sync()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "kA-GAzxBJDF4",
        "outputId": "612e5b6b-cfdb-4f2e-8925-72ad343ff4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|      | 636/1652 [02:11<03:21,  5.04it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mHit limit\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Hit limit</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|  | 1261/1652 [05:19<01:14,  5.27it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31mHit limit\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Hit limit</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1652/1652 [07:37<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Combined news data saved to: \u001b[35m/content/drive/\u001b[0m\u001b[95mMy\u001b[0m Drive/NCKH/news_data/03_primary/news.parquet\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Combined news data saved to: <span style=\"color: #800080; text-decoration-color: #800080\">/content/drive/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">My</span> Drive/NCKH/news_data/03_primary/news.parquet\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m(\u001b[0m\u001b[1;36m14748\u001b[0m, \u001b[1;36m9\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14748</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "f4ff548d",
        "outputId": "7572f733-03d2-423b-97f7-ed8a5bc6bc01"
      },
      "source": [
        "import polars as pl\n",
        "import os\n",
        "\n",
        "news_file_path = '/content/drive/My Drive/NCKH/news_data/03_primary/news.parquet'\n",
        "\n",
        "if os.path.exists(news_file_path):\n",
        "    news_df = pl.read_parquet(news_file_path)\n",
        "    print(\"News DataFrame loaded successfully.\")\n",
        "else:\n",
        "    print(f\"News file not found at: {news_file_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "News DataFrame loaded successfully.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">News DataFrame loaded successfully.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_df[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "IkrdqMesS3EJ",
        "outputId": "994be238-a463-4126-edaf-6212e161bae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "shape: \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m9\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              " author      content     datetime    source      title      url        date       equity \n",
              " ---         ---         ---         ---          ---        ---        ---        ---    \n",
              " str         str         datetime\u001b[1m[\u001b[0m  str          str        str        datetime\u001b[1m[\u001b[0m  str    \n",
              "                         s\u001b[1m]\u001b[0m                                             s\u001b[1m]\u001b[0m               \n",
              "\n",
              " Piero       \u001b[1m<\u001b[0m\u001b[1;95mp\u001b[0m\u001b[39m>In a     \u001b[0m\u001b[1;36m2024\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m06\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m14\u001b[0m\u001b[39m  benzinga    Inflation  \u001b[0m\u001b[4;94mhttps://w\u001b[0m\u001b[39m  \u001b[0m\u001b[1;36m2024\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m06\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m  MSFT   \u001b[0m\n",
              "\u001b[39m Cingari     week        \u001b[0m\u001b[1;92m20:06:26\u001b[0m\u001b[39m                 Cools In   ww.benzin  \u001b[0m\u001b[1;36m5\u001b[0m\u001b[39m                 \u001b[0m\n",
              "\u001b[39m             filled                               May, Fed   ga.com/ma  \u001b[0m\u001b[1;92m20:06:26\u001b[0m\u001b[39m          \u001b[0m\n",
              "\u001b[39m             with                                 Hi        rke                         \u001b[0m\n",
              "\u001b[39m             marke                                                                       \u001b[0m\n",
              "\u001b[39m Franca      <p>Starfie  \u001b[0m\u001b[1;36m2024\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m06\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m14\u001b[0m\u001b[39m  benzinga    Starfield  \u001b[0m\u001b[4;94mhttps://w\u001b[0m\u001b[39m  \u001b[0m\u001b[1;36m2024\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m06\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m  MSFT   \u001b[0m\n",
              "\u001b[39m Quarneti    ld, <stron  \u001b[0m\u001b[1;92m19:59:34\u001b[0m\u001b[39m                 Review     ww.benzin  \u001b[0m\u001b[1;36m5\u001b[0m\u001b[39m                 \u001b[0m\n",
              "\u001b[39m             g\u001b[0m\u001b[1m>\u001b[0mMicrosof                           Bomb:      ga.com/ge  \u001b[1;92m19:59:34\u001b[0m          \n",
              "                                                 Bethesd   ner                         \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">shape: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              " author      content     datetime    source      title      url        date       equity \n",
              " ---         ---         ---         ---          ---        ---        ---        ---    \n",
              " str         str         datetime<span style=\"font-weight: bold\">[</span>  str          str        str        datetime<span style=\"font-weight: bold\">[</span>  str    \n",
              "                         s<span style=\"font-weight: bold\">]</span>                                             s<span style=\"font-weight: bold\">]</span>               \n",
              "\n",
              " Piero       <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">p</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;In a     </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span><span style=\"color: #000000; text-decoration-color: #000000\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span><span style=\"color: #000000; text-decoration-color: #000000\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span><span style=\"color: #000000; text-decoration-color: #000000\">  benzinga    Inflation  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://w</span><span style=\"color: #000000; text-decoration-color: #000000\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span><span style=\"color: #000000; text-decoration-color: #000000\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span><span style=\"color: #000000; text-decoration-color: #000000\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #000000; text-decoration-color: #000000\">  MSFT   </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\"> Cingari     week        </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:06:26</span><span style=\"color: #000000; text-decoration-color: #000000\">                 Cools In   ww.benzin  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #000000; text-decoration-color: #000000\">                 </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">             filled                               May, Fed   ga.com/ma  </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">20:06:26</span><span style=\"color: #000000; text-decoration-color: #000000\">          </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">             with                                 Hi        rke                         </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">             marke                                                                       </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\"> Franca      &lt;p&gt;Starfie  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span><span style=\"color: #000000; text-decoration-color: #000000\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span><span style=\"color: #000000; text-decoration-color: #000000\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span><span style=\"color: #000000; text-decoration-color: #000000\">  benzinga    Starfield  </span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://w</span><span style=\"color: #000000; text-decoration-color: #000000\">  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span><span style=\"color: #000000; text-decoration-color: #000000\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span><span style=\"color: #000000; text-decoration-color: #000000\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #000000; text-decoration-color: #000000\">  MSFT   </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\"> Quarneti    ld, &lt;stron  </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:59:34</span><span style=\"color: #000000; text-decoration-color: #000000\">                 Review     ww.benzin  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #000000; text-decoration-color: #000000\">                 </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000\">             g</span><span style=\"font-weight: bold\">&gt;</span>Microsof                           Bomb:      ga.com/ge  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:59:34</span>          \n",
              "                                                 Bethesd   ner                         \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_df[0]['summary'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "7aZ9deloPXrJ",
        "outputId": "fe5a55f2-1b25-4c40-cc27-faaede5cd75f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "shape: \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m,\u001b[1m)\u001b[0m\n",
              "Series: \u001b[32m'summary'\u001b[0m \u001b[1m[\u001b[0mstr\u001b[1m]\u001b[0m\n",
              "\u001b[1m[\u001b[0m\n",
              "        \"Wall Street resilient as tech \n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">shape: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,<span style=\"font-weight: bold\">)</span>\n",
              "Series: <span style=\"color: #008000; text-decoration-color: #008000\">'summary'</span> <span style=\"font-weight: bold\">[</span>str<span style=\"font-weight: bold\">]</span>\n",
              "<span style=\"font-weight: bold\">[</span>\n",
              "        \"Wall Street resilient as tech \n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(news_df[0, 'summary'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "wdxnsCgoQG4F",
        "outputId": "5d312a05-73a5-467c-9681-890035f57b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "The Teamsters union on Tuesday announced that it ratified a landmark five-year collective bargaining agreement with\n",
              "the United Parcel Service.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The Teamsters union on Tuesday announced that it ratified a landmark five-year collective bargaining agreement with\n",
              "the United Parcel Service.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "381305a6"
      },
      "source": [
        "# 3. Aggregate Reuters news data with Alpaca"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Reuters crawling process is executed in another place. At this phase, i want to aggregate it into the fetched Alpaca news database."
      ],
      "metadata": {
        "id": "ArgaDQ-HU6jo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "f76607f3",
        "outputId": "d37b68aa-f306-4771-d839-de49c1fdbebf"
      },
      "source": [
        "news_df = news_df.with_columns(\n",
        "    pl.col(\"date\").cast(pl.Date)\n",
        ")\n",
        "\n",
        "print(news_df[\"date\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "shape: \u001b[1m(\u001b[0m14_748,\u001b[1m)\u001b[0m\n",
              "Series: \u001b[32m'date'\u001b[0m \u001b[1m[\u001b[0mdate\u001b[1m]\u001b[0m\n",
              "\u001b[1m[\u001b[0m\n",
              "        \u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m15\u001b[0m\n",
              "        \u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m15\u001b[0m\n",
              "        \u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m15\u001b[0m\n",
              "        \u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m15\u001b[0m\n",
              "        \u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m15\u001b[0m\n",
              "        \n",
              "        \u001b[1;36m2024\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m24\u001b[0m\n",
              "        \u001b[1;36m2024\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m24\u001b[0m\n",
              "        \u001b[1;36m2024\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m23\u001b[0m\n",
              "        \u001b[1;36m2024\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m23\u001b[0m\n",
              "        \u001b[1;36m2024\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m23\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">shape: <span style=\"font-weight: bold\">(</span>14_748,<span style=\"font-weight: bold\">)</span>\n",
              "Series: <span style=\"color: #008000; text-decoration-color: #008000\">'date'</span> <span style=\"font-weight: bold\">[</span>date<span style=\"font-weight: bold\">]</span>\n",
              "<span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>\n",
              "        \n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span>\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span>\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>\n",
              "        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c367bca",
        "outputId": "bf51656a-27af-4587-e4a3-7bf9aa3f06eb"
      },
      "source": [
        "import polars as pl\n",
        "import os\n",
        "\n",
        "news_file_path = '/content/drive/My Drive/NCKH/news_data/03_primary/news.parquet'\n",
        "sorted_news_file_path = '/content/drive/My Drive/NCKH/news_data/03_primary/news_sorted.parquet'\n",
        "\n",
        "\n",
        "if os.path.exists(news_file_path):\n",
        "    print(f\"Loading news data from: {news_file_path}\")\n",
        "    news_df = pl.read_parquet(news_file_path)\n",
        "\n",
        "    print(\"Sorting news data by 'datetime' in ascending order...\")\n",
        "    sorted_news_df = news_df.sort(\"datetime\", descending=False)\n",
        "\n",
        "    print(f\"Saving sorted news data to a new file: {sorted_news_file_path}\")\n",
        "    sorted_news_df.write_parquet(sorted_news_file_path)\n",
        "\n",
        "    print(\"Sorted news data saved successfully.\")\n",
        "else:\n",
        "    print(f\"News file not found at: {news_file_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading news data from: /content/drive/My Drive/NCKH/news_data/03_primary/news.parquet\n",
            "Sorting news data by 'datetime' in ascending order...\n",
            "Saving sorted news data to a new file: /content/drive/My Drive/NCKH/news_data/03_primary/news_sorted.parquet\n",
            "Sorted news data saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(sorted_news_file_path):\n",
        "    news_df = pl.read_parquet(sorted_news_file_path)\n",
        "    print(news_df[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIcB968zRoN6",
        "outputId": "c35769ea-4c09-4227-a033-5f576fff6092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (20, 9)\n",
            "\n",
            " author      content  datetime    source      title       url         date        equity \n",
            " ---         ---      ---         ---          ---         ---         ---         ---    \n",
            " str         str      datetime[  str          str         str         datetime[  str    \n",
            "                      s]                                               s]                 \n",
            "\n",
            " Jayson               2019-09-17  benzinga    Analyst On  https://ww  2019-09-18  MSFT   \n",
            " Derrick              17:26:14                 WeWork:     w.benzinga  09:00:00           \n",
            "                                               High        .com/analy                     \n",
            "                                               Growth                                   \n",
            " Shanthi              2020-04-30  benzinga    Microsoft   https://ww  2020-04-30  MSFT   \n",
            " Rexaline             15:47:08                 Analysts    w.benzinga  09:00:00           \n",
            "                                               On          .com/analy                     \n",
            "                                               Redmond'                                 \n",
            " Tanzeel              2020-05-13  benzinga    What To     https://ww  2020-05-14  AMZN   \n",
            " Akhtar               16:32:36                 Know About  w.benzinga  09:00:00           \n",
            "                                               The         .com/m-a/2                     \n",
            "                                               Conflic                                  \n",
            " Chris                2021-06-25  benzinga    Did Billio  https://ww  2021-06-26  TSLA   \n",
            " Katje                16:30:26                 naire Elon  w.benzinga  09:00:00           \n",
            "                                               Musk Sell  .com/news/                     \n",
            "                                                                                         \n",
            " Phil Hall            2021-09-20  benzinga    Elon Musk   https://ww  2021-09-20  TSLA   \n",
            "                      15:52:05                 Fails To    w.benzinga  09:00:00           \n",
            "                                               Get Buyer   .com/news/                     \n",
            "                                               F                                        \n",
            "                                                                                 \n",
            " Navdeep              2022-10-12  benzinga    Pro-Putin   https://ww  2022-10-12  TSLA   \n",
            " Yadav                09:16:16                 Hungarian   w.benzinga  09:00:00           \n",
            "                                               Leader      .com/news/                     \n",
            "                                               Joi                                      \n",
            " Navdeep              2022-10-14  benzinga    Ukraine     https://ww  2022-10-14  TSLA   \n",
            " Yadav                10:25:58                 Gets 150    w.benzinga  09:00:00           \n",
            "                                               Starlinks   .com/tech/                     \n",
            "                                               Fro                                      \n",
            " Shanthi              2023-03-09  benzinga    Meet        https://ww  2023-03-09  TSLA   \n",
            " Rexaline             10:02:07                 Tesla's     w.benzinga  09:00:00           \n",
            "                                               All-Star    .com/news/                     \n",
            "                                               Leadersh                                 \n",
            " Chris                2023-03-16  benzinga    A House     https://ww  2023-03-17  TSLA   \n",
            " Katje                20:42:35                 Equipped    w.benzinga  09:00:00           \n",
            "                                               With Tesla  .com/news/                     \n",
            "                                               So                                       \n",
            " Adam                 2023-04-19  benzinga    Orphan      https://ww  2023-04-20  AMZN   \n",
            " Eckert               21:38:55                 Living In   w.benzinga  09:00:00           \n",
            "                                               House       .com/news/                     \n",
            "                                               Without                                  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a. Fixing Datetime error."
      ],
      "metadata": {
        "id": "U4tdC1FwaTVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This show us that there are **223** instance that have `\"Null\"` value in column `Date`."
      ],
      "metadata": {
        "id": "hrmKggMKaY73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in news_df.columns:\n",
        "  print(f\"column: {col}, \", news_df[col].is_null().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "bkirRqYTTi2G",
        "outputId": "8e56859e-0800-4103-fa8a-c7c967af6f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "column: author,  \u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">column: author,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "column: content,  \u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">column: content,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "column: datetime,  \u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">column: datetime,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "column: source,  \u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">column: source,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "column: summary,  \u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">column: summary,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "column: title,  \u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">column: title,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "column: url,  \u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">column: url,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "column: date,  \u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">column: date,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "column: equity,  \u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">column: equity,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "column: year,  \u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">column: year,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "column: month,  \u001b[1;36m0\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">column: month,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This possibly because of the Error happens when we transform the original datetime to the roll-over datetime. The original logic in `round_to_next_day(`) functions show flaw in the instance that have \"datetime\" at the end of the month. So the \"+\" condition makes the date value falls out of appropriate date range -> Null when we apply `datetime()`."
      ],
      "metadata": {
        "id": "nRb4iau8akz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_instances = news_df.filter(pl.col(\"date\").is_null())\n",
        "null_instances[['datetime','date']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "XRPADa_YU2Kd",
        "outputId": "6f06b86a-550b-48b6-8102-0d34e77b90d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (0, 2)\n",
              "\n",
              " datetime      date \n",
              " ---           ---  \n",
              " datetime[s]  date \n",
              "\n",
              ""
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (0, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>datetime</th><th>date</th></tr><tr><td>datetime[s]</td><td>date</td></tr></thead><tbody></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapping the `\"Date\"` attribute again."
      ],
      "metadata": {
        "id": "_-sXsT1ubTnx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c70914bb",
        "outputId": "9fc702a2-4113-4f10-c1da-bcfd72e0863e"
      },
      "source": [
        "import polars as pl\n",
        "import os\n",
        "\n",
        "sorted_news_file_path = '/content/drive/My Drive/NCKH/news_data/03_primary/news_sorted.parquet'\n",
        "\n",
        "if os.path.exists(sorted_news_file_path):\n",
        "    print(f\"Loading sorted news data from: {sorted_news_file_path}\")\n",
        "    news_df = pl.read_parquet(sorted_news_file_path)\n",
        "\n",
        "    print(\"Recalculating 'date' column to fix nulls...\")\n",
        "\n",
        "    # Apply the condition and use offset_by to add a day where needed\n",
        "    news_df = news_df.with_columns(\n",
        "        pl.when(\n",
        "            (pl.col(\"datetime\").dt.hour() >= 16) & ((pl.col(\"datetime\").dt.minute() > 0) | (pl.col(\"datetime\").dt.second() > 0))\n",
        "        )\n",
        "        .then(pl.col(\"datetime\").dt.offset_by(\"1d\").cast(pl.Date))\n",
        "        .otherwise(pl.col(\"datetime\").cast(pl.Date))\n",
        "        .alias(\"date\")\n",
        "    )\n",
        "\n",
        "    print(f\"Saving corrected news data back to: {sorted_news_file_path}\")\n",
        "    news_df.write_parquet(sorted_news_file_path)\n",
        "\n",
        "    print(\"Corrected news data saved successfully.\")\n",
        "\n",
        "    # Verify that the nulls in 'date' are gone\n",
        "    null_count_after_fix = news_df[\"date\"].is_null().sum()\n",
        "    print(f\"Number of nulls in 'date' column after fix: {null_count_after_fix}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Sorted news file not found at: {sorted_news_file_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sorted news data from: /content/drive/My Drive/NCKH/news_data/03_primary/news_sorted.parquet\n",
            "Recalculating 'date' column to fix nulls...\n",
            "Saving corrected news data back to: /content/drive/My Drive/NCKH/news_data/03_primary/news_sorted.parquet\n",
            "Corrected news data saved successfully.\n",
            "Number of nulls in 'date' column after fix: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tracking the number of News for each tickets"
      ],
      "metadata": {
        "id": "avGaE3Oud6o1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tickets = [\"TSLA\", \"AMZN\", \"MSFT\", \"NFLX\"]\n",
        "total_news = [len(news_df.filter(pl.col(\"equity\") == ticket)) for ticket in tickets]\n",
        "for ticket, total_new in zip(tickets, total_news):\n",
        "  print(ticket, total_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "nF7Vnr2Qduik",
        "outputId": "e273aa45-aff0-4770-fdb8-a7a110b6de44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "TSLA \u001b[1;36m6220\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TSLA <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6220</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "AMZN \u001b[1;36m3448\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">AMZN <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3448</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "MSFT \u001b[1;36m4070\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">MSFT <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4070</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NFLX \u001b[1;36m1010\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">NFLX <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1010</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "107bb65a",
        "outputId": "160cf866-13e6-4812-db0f-aaafb1bc0619"
      },
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Extract year and month for grouping\n",
        "news_df = news_df.with_columns(\n",
        "    pl.col(\"date\").dt.year().alias(\"year\"),\n",
        "    pl.col(\"date\").dt.month().alias(\"month\")\n",
        ")\n",
        "\n",
        "# Group by equity, year, and month and count articles\n",
        "monthly_counts = news_df.group_by([\"equity\", \"year\", \"month\"]).agg(\n",
        "    pl.count().alias(\"article_count\")\n",
        ").sort([\"equity\", \"year\", \"month\"])\n",
        "\n",
        "# Convert month and year to string for better display in the chart\n",
        "monthly_counts = monthly_counts.with_columns(\n",
        "    pl.col(\"year\").cast(pl.Utf8),\n",
        "    pl.col(\"month\").cast(pl.Utf8)\n",
        ")\n",
        "\n",
        "# Create a combined month-year string for the x-axis\n",
        "monthly_counts = monthly_counts.with_columns(\n",
        "    (pl.col(\"year\") + \"-\" + pl.col(\"month\")).alias(\"year_month\")\n",
        ")\n",
        "\n",
        "\n",
        "# Convert Polars DataFrame to Pandas DataFrame for Plotly\n",
        "monthly_counts_pd = monthly_counts.to_pandas()\n",
        "\n",
        "# Create a bar chart\n",
        "fig = px.bar(monthly_counts_pd,\n",
        "             x=\"year_month\",\n",
        "             y=\"article_count\",\n",
        "             color=\"equity\",\n",
        "             title=\"Number of News Articles by Ticker and Month\",\n",
        "             labels={\"year_month\": \"Year-Month\", \"article_count\": \"Number of Articles\", \"equity\": \"Ticker\"})\n",
        "\n",
        "fig.update_layout(xaxis_tickangle=-45)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-24-514848126.py:11: DeprecationWarning:\n",
            "\n",
            "`pl.count()` is deprecated. Please use `pl.len()` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3d10c360-6ca8-4536-8084-1234abd7beac\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3d10c360-6ca8-4536-8084-1234abd7beac\")) {                    Plotly.newPlot(                        \"3d10c360-6ca8-4536-8084-1234abd7beac\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Ticker=AMZN\\u003cbr\\u003eYear-Month=%{x}\\u003cbr\\u003eNumber of Articles=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"AMZN\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"AMZN\",\"offsetgroup\":\"AMZN\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"2020-5\",\"2023-4\",\"2023-5\",\"2023-7\",\"2023-8\",\"2023-9\",\"2023-10\",\"2023-11\",\"2023-12\",\"2024-1\",\"2024-2\",\"2024-3\",\"2024-4\",\"2024-5\",\"2024-6\",\"2024-7\",\"2024-8\",\"2024-9\",\"2024-10\",\"2024-11\",\"2024-12\",\"2025-1\",\"2025-2\",\"2025-3\",\"2025-4\"],\"xaxis\":\"x\",\"y\":[1,1,1,1,76,181,205,178,167,191,186,144,167,189,153,184,164,160,165,182,177,161,160,160,94],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Ticker=MSFT\\u003cbr\\u003eYear-Month=%{x}\\u003cbr\\u003eNumber of Articles=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"MSFT\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"MSFT\",\"offsetgroup\":\"MSFT\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"2019-9\",\"2020-4\",\"2022-8\",\"2023-5\",\"2023-6\",\"2023-8\",\"2023-9\",\"2023-10\",\"2023-11\",\"2023-12\",\"2024-1\",\"2024-2\",\"2024-3\",\"2024-4\",\"2024-5\",\"2024-6\",\"2024-7\",\"2024-8\",\"2024-9\",\"2024-10\",\"2024-11\",\"2024-12\",\"2025-1\",\"2025-2\",\"2025-3\",\"2025-4\"],\"xaxis\":\"x\",\"y\":[1,1,1,1,1,111,239,281,254,239,238,230,197,217,259,194,249,166,153,193,177,139,184,129,141,75],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Ticker=NFLX\\u003cbr\\u003eYear-Month=%{x}\\u003cbr\\u003eNumber of Articles=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"NFLX\",\"marker\":{\"color\":\"#00cc96\",\"pattern\":{\"shape\":\"\"}},\"name\":\"NFLX\",\"offsetgroup\":\"NFLX\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"2021-10\",\"2022-8\",\"2023-8\",\"2023-9\",\"2023-10\",\"2023-11\",\"2023-12\",\"2024-1\",\"2024-2\",\"2024-3\",\"2024-4\",\"2024-5\",\"2024-6\",\"2024-7\",\"2024-8\",\"2024-9\",\"2024-10\",\"2024-11\",\"2024-12\",\"2025-1\",\"2025-2\",\"2025-3\",\"2025-4\"],\"xaxis\":\"x\",\"y\":[1,1,25,43,99,40,47,95,31,32,73,60,52,70,25,33,74,35,50,72,21,20,11],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Ticker=TSLA\\u003cbr\\u003eYear-Month=%{x}\\u003cbr\\u003eNumber of Articles=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"TSLA\",\"marker\":{\"color\":\"#ab63fa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"TSLA\",\"offsetgroup\":\"TSLA\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"2021-6\",\"2021-9\",\"2021-11\",\"2022-3\",\"2022-5\",\"2022-7\",\"2022-8\",\"2022-10\",\"2023-3\",\"2023-4\",\"2023-5\",\"2023-7\",\"2023-8\",\"2023-9\",\"2023-10\",\"2023-11\",\"2023-12\",\"2024-1\",\"2024-2\",\"2024-3\",\"2024-4\",\"2024-5\",\"2024-6\",\"2024-7\",\"2024-8\",\"2024-9\",\"2024-10\",\"2024-11\",\"2024-12\",\"2025-1\",\"2025-2\",\"2025-3\",\"2025-4\"],\"xaxis\":\"x\",\"y\":[1,1,2,1,1,2,1,2,2,1,2,3,171,341,358,306,328,364,286,315,436,318,270,444,232,204,342,282,263,281,223,321,116],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Year-Month\"},\"tickangle\":-45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Number of Articles\"}},\"legend\":{\"title\":{\"text\":\"Ticker\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Number of News Articles by Ticker and Month\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3d10c360-6ca8-4536-8084-1234abd7beac');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b. Aggregate Reuter data\n"
      ],
      "metadata": {
        "id": "HVeSnWHFkuwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "_c-r3VBIxfxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reuter_news_file = '/content/drive/My Drive/NCKH/news_data/03_primary/Reuters.xlsx'\n",
        "df = pd.read_excel(reuter_news_file)"
      ],
      "metadata": {
        "id": "FGC2lOLLwxjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iswRHa0hyfqW",
        "outputId": "16d2cd0b-a4bf-4d02-9c90-549f2a3434c3"
      },
      "source": [
        "import polars as pl\n",
        "\n",
        "reuters_df = pl.from_pandas(df)\n",
        "print(reuters_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (5, 4)\n",
            "\n",
            " Title                          datetime_utc         Content                        Stock_Type \n",
            " ---                            ---                  ---                            ---        \n",
            " str                            datetime[ns]         str                            str        \n",
            "\n",
            " Canada, inspired by EU and     2024-06-24 20:22:00  OTTAWA, June 24 (Reuters) -    Tesla      \n",
            " US,                                                Ca                                       \n",
            " Delaware law to allow big      2024-06-25 18:53:00  WILMINGTON, Delaware, June 25  Tesla      \n",
            " inve                                                                                        \n",
            " Electric-vehicle maker Rivian  2024-06-25 19:39:00  NORMAL, Illinois, June 24      Tesla      \n",
            "                                                    (Reu                                     \n",
            " Tesla recalls Cybertrucks      2024-06-26 05:38:00  WASHINGTON, June 25 (Reuters)  Tesla      \n",
            " over                                                                                        \n",
            " Berkshire Hathaway             2024-06-26 13:33:00  BEIJING/NEW YORK, June 25      Tesla      \n",
            " accelerates                                        (Reu                                     \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce65b15d"
      },
      "source": [
        "Rename the columns of the reuters_df Polars DataFrame to match the Alpaca news DataFrame schema and print the schema to verify.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29bf8c5d",
        "outputId": "4f136326-3e25-4930-e5f4-9c9636d43de1"
      },
      "source": [
        "reuters_df = reuters_df.rename({\n",
        "    'Title': 'title',\n",
        "    'datetime_utc': 'datetime',\n",
        "    'Content': 'content',\n",
        "    'Stock_Type': 'equity'\n",
        "})\n",
        "\n",
        "print(reuters_df.schema)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema([('title', String), ('datetime', Datetime(time_unit='ns', time_zone=None)), ('content', String), ('equity', String)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb317676",
        "outputId": "a74eeb2e-6621-40cf-a7fc-da3e4ed3ad2d"
      },
      "source": [
        "reuters_df = reuters_df.with_columns(\n",
        "    pl.col(\"datetime\").cast(pl.Date).alias(\"date\")\n",
        ")\n",
        "\n",
        "print(reuters_df[['datetime', 'date']].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (5, 2)\n",
            "\n",
            " datetime             date       \n",
            " ---                  ---        \n",
            " datetime[ns]         date       \n",
            "\n",
            " 2024-06-24 20:22:00  2024-06-24 \n",
            " 2024-06-25 18:53:00  2024-06-25 \n",
            " 2024-06-25 19:39:00  2024-06-25 \n",
            " 2024-06-26 05:38:00  2024-06-26 \n",
            " 2024-06-26 13:33:00  2024-06-26 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "661b16ad"
      },
      "source": [
        "Select and reorder the columns in the Reuters DataFrame to match the schema of the Alpaca news DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afc082dd",
        "outputId": "4fe853a8-eaa4-4f85-e1ec-b332198ad2a4"
      },
      "source": [
        "# Define the desired column order\n",
        "desired_columns = ['title', 'datetime', 'content', 'equity', 'date']\n",
        "\n",
        "# Select and reorder the columns\n",
        "reuters_df = reuters_df.select(desired_columns)\n",
        "\n",
        "# Print the schema to verify\n",
        "print(reuters_df.schema)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema([('title', String), ('datetime', Datetime(time_unit='ns', time_zone=None)), ('content', String), ('equity', String), ('date', Date)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ebf781d",
        "outputId": "6304cf82-2361-44e3-c8ad-9eaecf518bee"
      },
      "source": [
        "news_file_path = '/content/drive/My Drive/NCKH/news_data/03_primary/news.parquet'\n",
        "\n",
        "if os.path.exists(news_file_path):\n",
        "    news_df = pl.read_parquet(news_file_path)\n",
        "    print(\"News DataFrame loaded successfully.\")\n",
        "else:\n",
        "    print(f\"News file not found at: {news_file_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "News DataFrame loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfGAD7C9yxV_",
        "outputId": "4d11e063-e2a1-4ea8-d58b-8be692359208"
      },
      "source": [
        "print(\"Schema of news_df:\")\n",
        "print(news_df.schema)\n",
        "print(\"\\nSchema of reuters_df:\")\n",
        "print(reuters_df.schema)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema of news_df:\n",
            "Schema([('author', String), ('content', String), ('datetime', Datetime(time_unit='us', time_zone=None)), ('source', String), ('summary', String), ('title', String), ('url', String), ('date', Datetime(time_unit='us', time_zone=None)), ('equity', String)])\n",
            "\n",
            "Schema of reuters_df:\n",
            "Schema([('title', String), ('datetime', Datetime(time_unit='ns', time_zone=None)), ('content', String), ('equity', String), ('date', Date)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a60883ec"
      },
      "source": [
        "**Reasoning**:\n",
        "The schemas show that `news_df` has columns 'author', 'source', and 'summary' which are missing in `reuters_df`, and the 'date' column has different types. To make the schemas compatible for concatenation, I need to add the missing columns to `reuters_df` with null values and the correct data types, and ensure the 'date' column in `reuters_df` is of the same type as in `news_df`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O3LBAdIy02n",
        "outputId": "23aae90e-6606-4f9b-ceef-969e706af41e"
      },
      "source": [
        "reuters_df = reuters_df.with_columns([\n",
        "    pl.lit(None, dtype=pl.String).alias(\"author\"),\n",
        "    pl.lit(None, dtype=pl.String).alias(\"source\"),\n",
        "    pl.lit(None, dtype=pl.String).alias(\"summary\"),\n",
        "    pl.lit(None, dtype=pl.String).alias(\"url\") # Add the missing 'url' column\n",
        "])\n",
        "\n",
        "# Cast the 'datetime' column in reuters_df to match the time unit in news_df\n",
        "reuters_df = reuters_df.with_columns(\n",
        "    pl.col(\"datetime\").cast(pl.Datetime(time_unit='us')).alias(\"datetime\")\n",
        ")\n",
        "\n",
        "\n",
        "# Cast the 'date' column in reuters_df to match the type in news_df\n",
        "reuters_df = reuters_df.with_columns(\n",
        "    pl.col(\"date\").cast(pl.Datetime(time_unit='us')).alias(\"date\")\n",
        ")\n",
        "\n",
        "\n",
        "# Reorder columns of reuters_df to match news_df\n",
        "desired_columns = ['author', 'content', 'datetime', 'source', 'summary', 'title', 'url', 'date', 'equity']\n",
        "reuters_df = reuters_df.select(desired_columns)\n",
        "\n",
        "print(\"Schema of reuters_df after modification:\")\n",
        "print(reuters_df.schema)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema of reuters_df after modification:\n",
            "Schema([('author', String), ('content', String), ('datetime', Datetime(time_unit='us', time_zone=None)), ('source', String), ('summary', String), ('title', String), ('url', String), ('date', Datetime(time_unit='us', time_zone=None)), ('equity', String)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09525d27"
      },
      "source": [
        "**Reasoning**:\n",
        "The schema of `reuters_df` now matches the schema of `news_df`. I can now concatenate the two DataFrames, sort the combined DataFrame by date, and save it back to the parquet file as per the original instruction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4153ce2",
        "outputId": "15ec9ef5-ea00-4171-8f95-b4b1994a3d48"
      },
      "source": [
        "combined_df = pl.concat([news_df, reuters_df])\n",
        "\n",
        "sorted_combined_df = combined_df.sort(\"date\", descending=False)\n",
        "\n",
        "news_file_path = '/content/drive/My Drive/NCKH/news_data/03_primary/news.parquet'\n",
        "sorted_combined_df.write_parquet(news_file_path)\n",
        "\n",
        "print(f\"Combined and sorted news data saved to: {news_file_path}\")\n",
        "print(sorted_combined_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined and sorted news data saved to: /content/drive/My Drive/NCKH/news_data/03_primary/news.parquet\n",
            "(24338, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "062a1ffe"
      },
      "source": [
        "##3. Verify the result\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3ede772",
        "outputId": "894b8114-bd50-42a4-8c60-2282aed0bf63"
      },
      "source": [
        "news_file_path = '/content/drive/My Drive/NCKH/news_data/03_primary/news.parquet'\n",
        "\n",
        "# Load the combined and sorted parquet file\n",
        "combined_sorted_news_df = pl.read_parquet(news_file_path)\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"First 5 rows of the combined and sorted news DataFrame:\")\n",
        "print(combined_sorted_news_df.head())\n",
        "\n",
        "# Display the schema\n",
        "print(\"\\nSchema of the combined and sorted news DataFrame:\")\n",
        "print(combined_sorted_news_df.schema)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the combined and sorted news DataFrame:\n",
            "shape: (5, 9)\n",
            "\n",
            " author      content     datetime    source      title      url        date       equity \n",
            " ---         ---         ---         ---          ---        ---        ---        ---    \n",
            " str         str         datetime[  str          str        str        datetime[  str    \n",
            "                         s]                                             s]               \n",
            "\n",
            " Jayson      WeWork is   2019-09-17  benzinga    Analyst    https://w  2019-09-1  MSFT   \n",
            " Derrick     postponing  17:26:14                 On         ww.benzin  8                 \n",
            "             its initi                           WeWork:    ga.com/an  17:26:14          \n",
            "                                                  High       aly                         \n",
            "                                                  Growth                                 \n",
            " Shanthi     Microsoft   2020-04-30  benzinga    Microsoft  https://w  2020-04-3  MSFT   \n",
            " Rexaline    Corporatio  15:47:08                 Analysts   ww.benzin  0                 \n",
            "             n                                    On         ga.com/an  15:47:08          \n",
            "             (NASDAQ:                            Redmond'  aly                         \n",
            " Tanzeel     Editor's    2020-05-13  benzinga    What To    https://w  2020-05-1  AMZN   \n",
            " Akhtar      note: This  16:32:36                 Know       ww.benzin  4                 \n",
            "             story has                            About The  ga.com/m-  16:32:36          \n",
            "                                                 Conflic   a/2                         \n",
            " Chris       Despite a   2021-06-25  benzinga    Did Billi  https://w  2021-06-2  TSLA   \n",
            " Katje       wealth of   16:30:26                 onaire     ww.benzin  6                 \n",
            "             162.8                                Elon Musk  ga.com/ne  16:30:26          \n",
            "             bill                                Sell      ws/                         \n",
            " Phil Hall   Elon Musk   2021-09-20  benzinga    Elon Musk  https://w  2021-09-2  TSLA   \n",
            "             has taken   15:52:05                 Fails To   ww.benzin  0                 \n",
            "             his last                             Get Buyer  ga.com/ne  15:52:05          \n",
            "             r                                   F         ws/                         \n",
            "\n",
            "\n",
            "Schema of the combined and sorted news DataFrame:\n",
            "Schema([('author', String), ('content', String), ('datetime', Datetime(time_unit='us', time_zone=None)), ('source', String), ('summary', String), ('title', String), ('url', String), ('date', Datetime(time_unit='us', time_zone=None)), ('equity', String)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Process the Reuter datetime to match trading date."
      ],
      "metadata": {
        "id": "Gm1He2wsv-ta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reuter news datetime need to be align with the trading date in price data. Therefore, we need to map the datetime to the nearest trading date."
      ],
      "metadata": {
        "id": "g6CrQRyxVz1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "price_data_path = '/content/drive/My Drive/NCKH/price_data/price_data.pkl'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQPWyiE-wH2_",
        "outputId": "cdab69c3-f080-4119-9741-397c2472e925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "price_df = pd.read_pickle(price_data_path)\n",
        "print(price_df.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKR3A-18wg9R",
        "outputId": "0eada074-3573-4754-e9bd-7b3ce63e1d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys([datetime.date(2023, 8, 17), datetime.date(2023, 8, 18), datetime.date(2023, 8, 21), datetime.date(2023, 8, 22), datetime.date(2023, 8, 23), datetime.date(2023, 8, 24), datetime.date(2023, 8, 25), datetime.date(2023, 8, 28), datetime.date(2023, 8, 29), datetime.date(2023, 8, 30), datetime.date(2023, 8, 31), datetime.date(2023, 9, 1), datetime.date(2023, 9, 5), datetime.date(2023, 9, 6), datetime.date(2023, 9, 7), datetime.date(2023, 9, 8), datetime.date(2023, 9, 11), datetime.date(2023, 9, 12), datetime.date(2023, 9, 13), datetime.date(2023, 9, 14), datetime.date(2023, 9, 15), datetime.date(2023, 9, 18), datetime.date(2023, 9, 19), datetime.date(2023, 9, 20), datetime.date(2023, 9, 21), datetime.date(2023, 9, 22), datetime.date(2023, 9, 25), datetime.date(2023, 9, 26), datetime.date(2023, 9, 27), datetime.date(2023, 9, 28), datetime.date(2023, 9, 29), datetime.date(2023, 10, 2), datetime.date(2023, 10, 3), datetime.date(2023, 10, 4), datetime.date(2023, 10, 5), datetime.date(2023, 10, 6), datetime.date(2023, 10, 9), datetime.date(2023, 10, 10), datetime.date(2023, 10, 11), datetime.date(2023, 10, 12), datetime.date(2023, 10, 13), datetime.date(2023, 10, 16), datetime.date(2023, 10, 17), datetime.date(2023, 10, 18), datetime.date(2023, 10, 19), datetime.date(2023, 10, 20), datetime.date(2023, 10, 23), datetime.date(2023, 10, 24), datetime.date(2023, 10, 25), datetime.date(2023, 10, 26), datetime.date(2023, 10, 27), datetime.date(2023, 10, 30), datetime.date(2023, 10, 31), datetime.date(2023, 11, 1), datetime.date(2023, 11, 2), datetime.date(2023, 11, 3), datetime.date(2023, 11, 6), datetime.date(2023, 11, 7), datetime.date(2023, 11, 8), datetime.date(2023, 11, 9), datetime.date(2023, 11, 10), datetime.date(2023, 11, 13), datetime.date(2023, 11, 14), datetime.date(2023, 11, 15), datetime.date(2023, 11, 16), datetime.date(2023, 11, 17), datetime.date(2023, 11, 20), datetime.date(2023, 11, 21), datetime.date(2023, 11, 22), datetime.date(2023, 11, 24), datetime.date(2023, 11, 27), datetime.date(2023, 11, 28), datetime.date(2023, 11, 29), datetime.date(2023, 11, 30), datetime.date(2023, 12, 1), datetime.date(2023, 12, 4), datetime.date(2023, 12, 5), datetime.date(2023, 12, 6), datetime.date(2023, 12, 7), datetime.date(2023, 12, 8), datetime.date(2023, 12, 11), datetime.date(2023, 12, 12), datetime.date(2023, 12, 13), datetime.date(2023, 12, 14), datetime.date(2023, 12, 15), datetime.date(2023, 12, 18), datetime.date(2023, 12, 19), datetime.date(2023, 12, 20), datetime.date(2023, 12, 21), datetime.date(2023, 12, 22), datetime.date(2023, 12, 26), datetime.date(2023, 12, 27), datetime.date(2023, 12, 28), datetime.date(2023, 12, 29), datetime.date(2024, 1, 2), datetime.date(2024, 1, 3), datetime.date(2024, 1, 4), datetime.date(2024, 1, 5), datetime.date(2024, 1, 8), datetime.date(2024, 1, 9), datetime.date(2024, 1, 10), datetime.date(2024, 1, 11), datetime.date(2024, 1, 12), datetime.date(2024, 1, 16), datetime.date(2024, 1, 17), datetime.date(2024, 1, 18), datetime.date(2024, 1, 19), datetime.date(2024, 1, 22), datetime.date(2024, 1, 23), datetime.date(2024, 1, 24), datetime.date(2024, 1, 25), datetime.date(2024, 1, 26), datetime.date(2024, 1, 29), datetime.date(2024, 1, 30), datetime.date(2024, 1, 31), datetime.date(2024, 2, 1), datetime.date(2024, 2, 2), datetime.date(2024, 2, 5), datetime.date(2024, 2, 6), datetime.date(2024, 2, 7), datetime.date(2024, 2, 8), datetime.date(2024, 2, 9), datetime.date(2024, 2, 12), datetime.date(2024, 2, 13), datetime.date(2024, 2, 14), datetime.date(2024, 2, 15), datetime.date(2024, 2, 16), datetime.date(2024, 2, 20), datetime.date(2024, 2, 21), datetime.date(2024, 2, 22), datetime.date(2024, 2, 23), datetime.date(2024, 2, 26), datetime.date(2024, 2, 27), datetime.date(2024, 2, 28), datetime.date(2024, 2, 29), datetime.date(2024, 3, 1), datetime.date(2024, 3, 4), datetime.date(2024, 3, 5), datetime.date(2024, 3, 6), datetime.date(2024, 3, 7), datetime.date(2024, 3, 8), datetime.date(2024, 3, 11), datetime.date(2024, 3, 12), datetime.date(2024, 3, 13), datetime.date(2024, 3, 14), datetime.date(2024, 3, 15), datetime.date(2024, 3, 18), datetime.date(2024, 3, 19), datetime.date(2024, 3, 20), datetime.date(2024, 3, 21), datetime.date(2024, 3, 22), datetime.date(2024, 3, 25), datetime.date(2024, 3, 26), datetime.date(2024, 3, 27), datetime.date(2024, 3, 28), datetime.date(2024, 4, 1), datetime.date(2024, 4, 2), datetime.date(2024, 4, 3), datetime.date(2024, 4, 4), datetime.date(2024, 4, 5), datetime.date(2024, 4, 8), datetime.date(2024, 4, 9), datetime.date(2024, 4, 10), datetime.date(2024, 4, 11), datetime.date(2024, 4, 12), datetime.date(2024, 4, 15), datetime.date(2024, 4, 16), datetime.date(2024, 4, 17), datetime.date(2024, 4, 18), datetime.date(2024, 4, 19), datetime.date(2024, 4, 22), datetime.date(2024, 4, 23), datetime.date(2024, 4, 24), datetime.date(2024, 4, 25), datetime.date(2024, 4, 26), datetime.date(2024, 4, 29), datetime.date(2024, 4, 30), datetime.date(2024, 5, 1), datetime.date(2024, 5, 2), datetime.date(2024, 5, 3), datetime.date(2024, 5, 6), datetime.date(2024, 5, 7), datetime.date(2024, 5, 8), datetime.date(2024, 5, 9), datetime.date(2024, 5, 10), datetime.date(2024, 5, 13), datetime.date(2024, 5, 14), datetime.date(2024, 5, 15), datetime.date(2024, 5, 16), datetime.date(2024, 5, 17), datetime.date(2024, 5, 20), datetime.date(2024, 5, 21), datetime.date(2024, 5, 22), datetime.date(2024, 5, 23), datetime.date(2024, 5, 24), datetime.date(2024, 5, 28), datetime.date(2024, 5, 29), datetime.date(2024, 5, 30), datetime.date(2024, 5, 31), datetime.date(2024, 6, 3), datetime.date(2024, 6, 4), datetime.date(2024, 6, 5), datetime.date(2024, 6, 6), datetime.date(2024, 6, 7), datetime.date(2024, 6, 10), datetime.date(2024, 6, 11), datetime.date(2024, 6, 12), datetime.date(2024, 6, 13), datetime.date(2024, 6, 14), datetime.date(2024, 6, 17), datetime.date(2024, 6, 18), datetime.date(2024, 6, 20), datetime.date(2024, 6, 21), datetime.date(2024, 6, 24), datetime.date(2024, 6, 25), datetime.date(2024, 6, 26), datetime.date(2024, 6, 27), datetime.date(2024, 6, 28), datetime.date(2024, 7, 1), datetime.date(2024, 7, 2), datetime.date(2024, 7, 3), datetime.date(2024, 7, 5), datetime.date(2024, 7, 8), datetime.date(2024, 7, 9), datetime.date(2024, 7, 10), datetime.date(2024, 7, 11), datetime.date(2024, 7, 12), datetime.date(2024, 7, 15), datetime.date(2024, 7, 16), datetime.date(2024, 7, 17), datetime.date(2024, 7, 18), datetime.date(2024, 7, 19), datetime.date(2024, 7, 22), datetime.date(2024, 7, 23), datetime.date(2024, 7, 24), datetime.date(2024, 7, 25), datetime.date(2024, 7, 26), datetime.date(2024, 7, 29), datetime.date(2024, 7, 30), datetime.date(2024, 7, 31), datetime.date(2024, 8, 1), datetime.date(2024, 8, 2), datetime.date(2024, 8, 5), datetime.date(2024, 8, 6), datetime.date(2024, 8, 7), datetime.date(2024, 8, 8), datetime.date(2024, 8, 9), datetime.date(2024, 8, 12), datetime.date(2024, 8, 13), datetime.date(2024, 8, 14), datetime.date(2024, 8, 15), datetime.date(2024, 8, 16), datetime.date(2024, 8, 19), datetime.date(2024, 8, 20), datetime.date(2024, 8, 21), datetime.date(2024, 8, 22), datetime.date(2024, 8, 23), datetime.date(2024, 8, 26), datetime.date(2024, 8, 27), datetime.date(2024, 8, 28), datetime.date(2024, 8, 29), datetime.date(2024, 8, 30), datetime.date(2024, 9, 3), datetime.date(2024, 9, 4), datetime.date(2024, 9, 5), datetime.date(2024, 9, 6), datetime.date(2024, 9, 9), datetime.date(2024, 9, 10), datetime.date(2024, 9, 11), datetime.date(2024, 9, 12), datetime.date(2024, 9, 13), datetime.date(2024, 9, 16), datetime.date(2024, 9, 17), datetime.date(2024, 9, 18), datetime.date(2024, 9, 19), datetime.date(2024, 9, 20), datetime.date(2024, 9, 23), datetime.date(2024, 9, 24), datetime.date(2024, 9, 25), datetime.date(2024, 9, 26), datetime.date(2024, 9, 27), datetime.date(2024, 9, 30), datetime.date(2024, 10, 1), datetime.date(2024, 10, 2), datetime.date(2024, 10, 3), datetime.date(2024, 10, 4), datetime.date(2024, 10, 7), datetime.date(2024, 10, 8), datetime.date(2024, 10, 9), datetime.date(2024, 10, 10), datetime.date(2024, 10, 11), datetime.date(2024, 10, 14), datetime.date(2024, 10, 15), datetime.date(2024, 10, 16), datetime.date(2024, 10, 17), datetime.date(2024, 10, 18), datetime.date(2024, 10, 21), datetime.date(2024, 10, 22), datetime.date(2024, 10, 23), datetime.date(2024, 10, 24), datetime.date(2024, 10, 25), datetime.date(2024, 10, 28), datetime.date(2024, 10, 29), datetime.date(2024, 10, 30), datetime.date(2024, 10, 31), datetime.date(2024, 11, 1), datetime.date(2024, 11, 4), datetime.date(2024, 11, 5), datetime.date(2024, 11, 6), datetime.date(2024, 11, 7), datetime.date(2024, 11, 8), datetime.date(2024, 11, 11), datetime.date(2024, 11, 12), datetime.date(2024, 11, 13), datetime.date(2024, 11, 14), datetime.date(2024, 11, 15), datetime.date(2024, 11, 18), datetime.date(2024, 11, 19), datetime.date(2024, 11, 20), datetime.date(2024, 11, 21), datetime.date(2024, 11, 22), datetime.date(2024, 11, 25), datetime.date(2024, 11, 26), datetime.date(2024, 11, 27), datetime.date(2024, 11, 29), datetime.date(2024, 12, 2), datetime.date(2024, 12, 3), datetime.date(2024, 12, 4), datetime.date(2024, 12, 5), datetime.date(2024, 12, 6), datetime.date(2024, 12, 9), datetime.date(2024, 12, 10), datetime.date(2024, 12, 11), datetime.date(2024, 12, 12), datetime.date(2024, 12, 13), datetime.date(2024, 12, 16), datetime.date(2024, 12, 17), datetime.date(2024, 12, 18), datetime.date(2024, 12, 19), datetime.date(2024, 12, 20), datetime.date(2024, 12, 23), datetime.date(2024, 12, 24), datetime.date(2024, 12, 26), datetime.date(2024, 12, 27), datetime.date(2024, 12, 30), datetime.date(2024, 12, 31), datetime.date(2025, 1, 2), datetime.date(2025, 1, 3), datetime.date(2025, 1, 6), datetime.date(2025, 1, 7), datetime.date(2025, 1, 8), datetime.date(2025, 1, 10), datetime.date(2025, 1, 13), datetime.date(2025, 1, 14), datetime.date(2025, 1, 15), datetime.date(2025, 1, 16), datetime.date(2025, 1, 17), datetime.date(2025, 1, 21), datetime.date(2025, 1, 22), datetime.date(2025, 1, 23), datetime.date(2025, 1, 24), datetime.date(2025, 1, 27), datetime.date(2025, 1, 28), datetime.date(2025, 1, 29), datetime.date(2025, 1, 30), datetime.date(2025, 1, 31), datetime.date(2025, 2, 3), datetime.date(2025, 2, 4), datetime.date(2025, 2, 5), datetime.date(2025, 2, 6), datetime.date(2025, 2, 7), datetime.date(2025, 2, 10), datetime.date(2025, 2, 11), datetime.date(2025, 2, 12), datetime.date(2025, 2, 13), datetime.date(2025, 2, 14), datetime.date(2025, 2, 18), datetime.date(2025, 2, 19), datetime.date(2025, 2, 20), datetime.date(2025, 2, 21), datetime.date(2025, 2, 24), datetime.date(2025, 2, 25), datetime.date(2025, 2, 26), datetime.date(2025, 2, 27), datetime.date(2025, 2, 28), datetime.date(2025, 3, 3), datetime.date(2025, 3, 4), datetime.date(2025, 3, 5), datetime.date(2025, 3, 6), datetime.date(2025, 3, 7), datetime.date(2025, 3, 10), datetime.date(2025, 3, 11), datetime.date(2025, 3, 12), datetime.date(2025, 3, 13), datetime.date(2025, 3, 14), datetime.date(2025, 3, 17), datetime.date(2025, 3, 18), datetime.date(2025, 3, 19), datetime.date(2025, 3, 20), datetime.date(2025, 3, 21), datetime.date(2025, 3, 24), datetime.date(2025, 3, 25), datetime.date(2025, 3, 26), datetime.date(2025, 3, 27), datetime.date(2025, 3, 28), datetime.date(2025, 3, 31), datetime.date(2025, 4, 1), datetime.date(2025, 4, 2), datetime.date(2025, 4, 3), datetime.date(2025, 4, 4), datetime.date(2025, 4, 7), datetime.date(2025, 4, 8), datetime.date(2025, 4, 9)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dictionary to a pandas DataFrame\n",
        "price_df = pd.DataFrame.from_dict(price_df, orient='index')\n",
        "price_df.index.name = 'date'\n",
        "price_df = price_df.reset_index()\n",
        "\n",
        "print(price_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-xY0QobyoOg",
        "outputId": "5c28eb8f-3002-4f13-ee44-9c18deb432d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         date                                              price\n",
            "0  2023-08-17  {'TSLA': 219.22000122070312, 'AMZN': 133.97999...\n",
            "1  2023-08-18  {'TSLA': 215.49000549316406, 'AMZN': 133.22000...\n",
            "2  2023-08-21  {'TSLA': 231.27999877929688, 'AMZN': 134.67999...\n",
            "3  2023-08-22  {'TSLA': 233.19000244140625, 'AMZN': 134.25, '...\n",
            "4  2023-08-23  {'TSLA': 236.86000061035156, 'AMZN': 135.52000...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta\n",
        "def adjust_trading_days(df: pd.DataFrame, trading_dates: list) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Adjusts dates in the DataFrame to the nearest following trading day,\n",
        "    using a pre-fetched list of trading dates.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The DataFrame with a 'date' column to be adjusted.\n",
        "        trading_dates (list or set): List or set of valid trading datetime.date objects.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame with adjusted 'date' column.\n",
        "    \"\"\"\n",
        "    # Ensure 'date' column is datetime and normalized (no time part)\n",
        "    df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
        "\n",
        "    # Convert trading_dates to a sorted list of datetime.date for iteration\n",
        "    trading_dates = sorted(pd.to_datetime(trading_dates).normalize())\n",
        "\n",
        "    # For faster lookup\n",
        "    trading_set = set(trading_dates)\n",
        "\n",
        "    # Adjust dates\n",
        "    adjusted_dates = []\n",
        "    for current_date in df['date']:\n",
        "        adjusted_date = current_date\n",
        "        while adjusted_date not in trading_set:\n",
        "            adjusted_date += timedelta(days=1)\n",
        "        adjusted_dates.append(adjusted_date)\n",
        "\n",
        "    df['date'] = adjusted_dates\n",
        "    return df"
      ],
      "metadata": {
        "id": "2j96Wf-O0uap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Running this is possible, but the nested loop makes it extremely time-consuming.\n",
        "# df_raw_adjusted = adjust_trading_days(news_raw, trading_date)"
      ],
      "metadata": {
        "id": "5vry3WI33Lge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "def build_trading_date_map(trading_dates, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Builds a mapping from each calendar date in the range to the next trading day.\n",
        "    Uses tqdm for progress visualization.\n",
        "\n",
        "    Parameters:\n",
        "        trading_dates (list or Series): A list of valid trading dates.\n",
        "        start_date (datetime): Start of calendar date range.\n",
        "        end_date (datetime): End of calendar date range.\n",
        "\n",
        "    Returns:\n",
        "        dict: A mapping from each calendar date to the next trading day.\n",
        "    \"\"\"\n",
        "    trading_dates = pd.to_datetime(sorted(pd.to_datetime(trading_dates).normalize()))\n",
        "    calendar_dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
        "\n",
        "    mapping = {}\n",
        "    trading_idx = 0\n",
        "\n",
        "    for date in tqdm(calendar_dates, desc=\"Building trading date map\"):\n",
        "        while trading_idx < len(trading_dates) and trading_dates[trading_idx] < date:\n",
        "            trading_idx += 1\n",
        "        if trading_idx < len(trading_dates):\n",
        "            mapping[date] = trading_dates[trading_idx]\n",
        "        else:\n",
        "            mapping[date] = trading_dates[-1]  # fallback if out of range\n",
        "\n",
        "    return mapping\n"
      ],
      "metadata": {
        "id": "2XNI6svE5zCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def adjust_trading_days_fast(df, trading_date_map):\n",
        "    \"\"\"\n",
        "    Adjusts dates in a DataFrame to the next trading day using a precomputed map.\n",
        "    Shows progress using tqdm.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): The DataFrame with a 'date' column.\n",
        "        trading_date_map (dict): Mapping from raw dates to trading dates.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Updated DataFrame with adjusted 'date' column.\n",
        "    \"\"\"\n",
        "    df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
        "    tqdm.pandas(desc=\"Adjusting to trading days\")\n",
        "    df['date'] = df['date'].progress_map(lambda x: trading_date_map.get(x, x))\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "G--_Z4Nd8UVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_data_path = '/content/drive/My Drive/NCKH/news_data/concatenated_news_filtered.parquet'\n",
        "news_data = pd.read_parquet(news_data_path)\n",
        "news_data['date'] = pd.to_datetime(news_data['date']).dt.normalize()"
      ],
      "metadata": {
        "id": "yqcKYLf4z7rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trading_date = price_df['date'].tolist()\n",
        "news_raw = news_data[~news_data['date'].isin(trading_date)] #4468\n",
        "news_processed = news_data[news_data['date'].isin(trading_date)] #19832"
      ],
      "metadata": {
        "id": "kNpTJADk8-M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = news_data['date'].min()\n",
        "end_date = news_data['date'].max()\n",
        "\n",
        "# Build the fast lookup mapping\n",
        "trading_date_map = build_trading_date_map(trading_date, start_date, end_date)\n",
        "\n",
        "# Adjust in ~O(n) with mapping\n",
        "df_adjusted = adjust_trading_days_fast(news_raw, trading_date_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFVHJGLH8XKy",
        "outputId": "cee8ad05-9e2a-47a7-f05e-d004f19bb2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building trading date map: 100%|| 2110/2110 [00:00<00:00, 89556.58it/s]\n",
            "/tmp/ipython-input-37-3016348647.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['date'] = pd.to_datetime(df['date']).dt.normalize()\n",
            "Adjusting to trading days: 100%|| 4468/4468 [00:00<00:00, 285559.84it/s]\n",
            "/tmp/ipython-input-37-3016348647.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['date'] = df['date'].progress_map(lambda x: trading_date_map.get(x, x))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = pd.concat([news_processed, df_adjusted]).sort_values(by='date').reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "emn8y8aN-Ha5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_clean[~df_clean['date'].isin(trading_date)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq78rm11-Wyr",
        "outputId": "6d6bdb4b-539a-4488-a523-9fbe746118c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to save the processed data\n",
        "processed_news_path = '/content/drive/My Drive/NCKH/news_data/concatenated_news_filtered.parquet'\n",
        "\n",
        "# Save the df_clean DataFrame to the specified path, overwriting the existing file\n",
        "df_clean.to_parquet(processed_news_path, index=False)\n",
        "\n",
        "print(f\"Processed and cleaned news data saved to: {processed_news_path}\")\n",
        "print(df_clean.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGZVAdCX-lQs",
        "outputId": "24d5aa88-2034-409d-b820-28c9396f9690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed and cleaned news data saved to: /content/drive/My Drive/NCKH/news_data/concatenated_news_filtered.parquet\n",
            "(24300, 13)\n"
          ]
        }
      ]
    }
  ]
}